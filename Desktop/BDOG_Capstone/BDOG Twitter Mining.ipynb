{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweets with GU-related hashtags into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "from datetime import datetime\n",
    "\n",
    "# Twitter credentials for the app\n",
    "consumer_key = 'PUJGbYNh7t5Wdf19pid0F339i'\n",
    "consumer_secret = 'TkiY2twuL5DsNzHkcYO1Cyv1xXGXi05qGTMbhDIcIsQUKnL1PD'\n",
    "access_key= '1026361616604913664-8gQFpa8Ea6hpUPTgr1vdGHxwb4yqKE'\n",
    "access_secret = 'bhN75eHt2GCFGN5slOpZCam4nMNKQVgqK82AbQaFvLwVX'\n",
    "\n",
    "# Pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Set dataframe columns\n",
    "COLS = ['hashtag','created_at','text','source','geo','user_id','user_location','user_followers','user_friends','retweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch tweets, save to csv read as dataframe\n",
    "def ForEachHashtag(hashtag):\n",
    "    # Open/Create a file to append data\n",
    "    csvFile = open(\"{}{}\".format(hashtag, \".csv\"), 'w')\n",
    "    \n",
    "    #Use csv Writer\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    i=0\n",
    "    for tweet in tweepy.Cursor(api.search,q=\"#\"+hashtag, count = 100, lang=\"en\",).items():\n",
    "        #print(i,end='\\r')\n",
    "        csvWriter.writerow([hashtag,tweet.created_at, tweet.text.encode('utf-8'), tweet.source, \n",
    "                             tweet.geo, tweet.user.id, tweet.user.location,tweet.user.followers_count, \n",
    "                             tweet.user.friends_count, tweet.retweet_count])\n",
    "        i=i+1\n",
    "    df = pd.read_csv(\"{}{}\".format(hashtag, \".csv\"), header = None)\n",
    "    df.columns = COLS\n",
    "    df = df[df['text'].notna()]\n",
    "    return(df)\n",
    "    \n",
    "#ForEachHashtag(\"hoya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoya\n",
      "hoyas\n",
      "georgetown\n",
      "georgetownuniversity\n",
      "hoyasaxa\n"
     ]
    }
   ],
   "source": [
    "def FetchAllHashtags(list_of_hashtags):\n",
    "    df = pd.DataFrame(columns = COLS)\n",
    "    list_of_df = []\n",
    "    for i in list_of_hashtags:\n",
    "        print(i)\n",
    "        list_of_df.append(ForEachHashtag(i))\n",
    "    res = pd.concat(list_of_df)\n",
    "    res.to_csv(r\"big_df.csv\", index = None, header = True)\n",
    "    return(res)\n",
    "\n",
    "big_df = FetchAllHashtags(['hoya','hoyas','georgetown','georgetownuniversity','hoyasaxa'])  #'jackthebulldog'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>geo</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>hoya</td>\n",
       "      <td>2020-02-21 13:32:32</td>\n",
       "      <td>b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3478632974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>358</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hoya</td>\n",
       "      <td>2020-02-21 13:31:53</td>\n",
       "      <td>b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>861569795904258049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>429</td>\n",
       "      <td>2128</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hoya</td>\n",
       "      <td>2020-02-21 10:12:07</td>\n",
       "      <td>b'RT @ChewieKpop: INFINITE DESTINY in America\\...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1126491750263132160</td>\n",
       "      <td>Japan</td>\n",
       "      <td>164</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>hoya</td>\n",
       "      <td>2020-02-21 09:51:15</td>\n",
       "      <td>b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779386332628021249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539</td>\n",
       "      <td>527</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>hoya</td>\n",
       "      <td>2020-02-21 07:48:33</td>\n",
       "      <td>b\"RT @HowonUpdates: [INFO] 200220 #HOYA replie...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1094398367868674048</td>\n",
       "      <td>Cebu_인피니트</td>\n",
       "      <td>282</td>\n",
       "      <td>562</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1109</td>\n",
       "      <td>hoyasaxa</td>\n",
       "      <td>2020-02-12 16:35:26</td>\n",
       "      <td>b'Meeting &amp;amp; befriending @Briebrunnin remai...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3298774073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10893</td>\n",
       "      <td>3130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>hoyasaxa</td>\n",
       "      <td>2020-02-12 16:33:57</td>\n",
       "      <td>b'#startupgrind2020  with the DMV and @Halcyon...</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [37.4849, -12...</td>\n",
       "      <td>87440584</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>84</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1111</td>\n",
       "      <td>hoyasaxa</td>\n",
       "      <td>2020-02-12 15:51:39</td>\n",
       "      <td>b'RT @HoyasMLacrosse: Check out the new white ...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3143645973</td>\n",
       "      <td>Ellicott City, MD</td>\n",
       "      <td>91</td>\n",
       "      <td>380</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1112</td>\n",
       "      <td>hoyasaxa</td>\n",
       "      <td>2020-02-12 15:15:44</td>\n",
       "      <td>b'RT @JulianDionG: The steps at Savoy Elementa...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>883846221185642496</td>\n",
       "      <td>North Miami, FL</td>\n",
       "      <td>49</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>hoyasaxa</td>\n",
       "      <td>2020-02-12 15:06:45</td>\n",
       "      <td>b'RT @HilltopShow: ANNOUNCING: We will be cond...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>906623125</td>\n",
       "      <td>Georgetown, Washington</td>\n",
       "      <td>435</td>\n",
       "      <td>1663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3407 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hashtag           created_at  \\\n",
       "0         hoya  2020-02-21 13:32:32   \n",
       "1         hoya  2020-02-21 13:31:53   \n",
       "2         hoya  2020-02-21 10:12:07   \n",
       "3         hoya  2020-02-21 09:51:15   \n",
       "4         hoya  2020-02-21 07:48:33   \n",
       "...        ...                  ...   \n",
       "1109  hoyasaxa  2020-02-12 16:35:26   \n",
       "1110  hoyasaxa  2020-02-12 16:33:57   \n",
       "1111  hoyasaxa  2020-02-12 15:51:39   \n",
       "1112  hoyasaxa  2020-02-12 15:15:44   \n",
       "1113  hoyasaxa  2020-02-12 15:06:45   \n",
       "\n",
       "                                                   text               source  \\\n",
       "0     b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...  Twitter for Android   \n",
       "1     b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...      Twitter Web App   \n",
       "2     b'RT @ChewieKpop: INFINITE DESTINY in America\\...   Twitter for iPhone   \n",
       "3     b'RT @HowonUpdates: [VID] 200220 Kiseop Instag...  Twitter for Android   \n",
       "4     b\"RT @HowonUpdates: [INFO] 200220 #HOYA replie...  Twitter for Android   \n",
       "...                                                 ...                  ...   \n",
       "1109  b'Meeting &amp; befriending @Briebrunnin remai...      Twitter Web App   \n",
       "1110  b'#startupgrind2020  with the DMV and @Halcyon...            Instagram   \n",
       "1111  b'RT @HoyasMLacrosse: Check out the new white ...      Twitter Web App   \n",
       "1112  b'RT @JulianDionG: The steps at Savoy Elementa...   Twitter for iPhone   \n",
       "1113  b'RT @HilltopShow: ANNOUNCING: We will be cond...   Twitter for iPhone   \n",
       "\n",
       "                                                    geo              user_id  \\\n",
       "0                                                   NaN           3478632974   \n",
       "1                                                   NaN   861569795904258049   \n",
       "2                                                   NaN  1126491750263132160   \n",
       "3                                                   NaN   779386332628021249   \n",
       "4                                                   NaN  1094398367868674048   \n",
       "...                                                 ...                  ...   \n",
       "1109                                                NaN           3298774073   \n",
       "1110  {'type': 'Point', 'coordinates': [37.4849, -12...             87440584   \n",
       "1111                                                NaN           3143645973   \n",
       "1112                                                NaN   883846221185642496   \n",
       "1113                                                NaN            906623125   \n",
       "\n",
       "               user_location  user_followers  user_friends  retweet  \n",
       "0                        NaN              88           358       60  \n",
       "1                        NaN             429          2128       60  \n",
       "2                      Japan             164            80        5  \n",
       "3                        NaN             539           527       60  \n",
       "4                  Cebu_인피니트             282           562       36  \n",
       "...                      ...             ...           ...      ...  \n",
       "1109                     NaN           10893          3130        0  \n",
       "1110           Arlington, VA              84           167        0  \n",
       "1111       Ellicott City, MD              91           380       17  \n",
       "1112         North Miami, FL              49           136        1  \n",
       "1113  Georgetown, Washington             435          1663        1  \n",
       "\n",
       "[3407 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis with NLTK and Spacy (linguistic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#list of words I have seen\n",
    "seenit=[]\n",
    "#dict of word counts\n",
    "WordDict={}\n",
    "Rawfilename=\"TwitterResultsRaw.txt\"\n",
    "Freqfilename=\"TwitterWordFrq.txt\"\n",
    "\n",
    "\n",
    "#FILE=open(Freqfilename,\"w\")\n",
    "#FILE2=open(Rawfilename, \"w\")\n",
    "R_FILE=open(Rawfilename,\"w\")\n",
    "F_FILE=open(Freqfilename, \"w\")\n",
    "\n",
    "IgnoreThese=[\"and\", \"And\", \"AND\",\"THIS\", \"This\", \"this\", \"for\", \"FOR\", \"For\", \n",
    "             \"THE\", \"The\", \"the\", \"is\", \"IS\", \"Is\", \"or\", \"OR\", \"Or\", \"will\", \n",
    "             \"Will\", \"WILL\", \"God\", \"god\", \"GOD\", \"Bible\", \"bible\", \"BIBLE\",\n",
    "             \"CanChew\", \"Download\", \"free\", \"FREE\", \"Free\", \"will\", \"WILL\", \n",
    "             \"Will\", \"hits\", \"hit\", \"within\", \"steam\", \"Via\", \"via\", \"know\", \"Study\",\n",
    "             \"study\", \"unit\", \"Unit\", \"always\", \"take\", \"Take\", \"left\", \"Left\",\n",
    "             \"lot\",\"robot\", \"Robot\", \"Lot\", \"last\", \"Last\", \"Wonder\", \"still\", \"Still\",\n",
    "             \"ferocious\", \"Need\", \"need\", \"food\", \"Food\", \"Flint\", \"MachineCredit\",\n",
    "             \"Webchat\", \"luxury\", \"full\", \"fifdh17\", \"New\", \"new\", \"Caroline\",\n",
    "             \"Tirana\", \"Shuayb\", \"repro\", \"attempted\", \"key\", \"Harrient\", \n",
    "             \"Chavez\", \"Women\", \"women\", \"Mumsnet\", \"Ali\", \"Tubman\", \"girl\",\"Girl\",\n",
    "             \"CSW61\", \"IWD2017\", \"Harriet\", \"Great\", \"great\", \"single\", \"Single\", \n",
    "             \"tailoring\", \"ask\", \"Ask\"]\n",
    "###Look at the words\n",
    "for w in BigBag:\n",
    "    if(w not in IgnoreThese):\n",
    "        rawWord=w+\" \"\n",
    "        R_FILE.write(rawWord)\n",
    "        if(w in seenit):\n",
    "            #print(w, seenit)\n",
    "            WordDict[w]=WordDict[w]+1 #increment the times word is seen\n",
    "        else:\n",
    "            ##add word to dict and seenit\n",
    "            seenit.append(w)\n",
    "            WordDict[w]=1\n",
    "    \n",
    "#print(WordDict)  \n",
    "#print(seenit)\n",
    "#print(BagOfWords)\n",
    "\n",
    "\n",
    "\n",
    "for key in WordDict:\n",
    "    #print(WordDict[key])\n",
    "    if(WordDict[key]>1):\n",
    "        if(key not in IgnoreThese):\n",
    "            #print(key)\n",
    "            Key_Value=key + \",\" + str(WordDict[key]) + \"\\n\"\n",
    "            F_FILE.write(Key_Value)\n",
    "\n",
    "\n",
    "#FILE.close()\n",
    "#FILE2.close()\n",
    "R_FILE.close()\n",
    "F_FILE.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification/regression, cluster, network, statistical models, neural net with word2vec etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
